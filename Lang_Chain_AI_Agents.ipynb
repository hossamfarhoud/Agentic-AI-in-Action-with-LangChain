{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Packages"
      ],
      "metadata": {
        "id": "7Luc20QVhqin"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yrQYthRHdCc"
      },
      "outputs": [],
      "source": [
        "!pip install openai --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install cohere --quiet\n",
        "!pip install langchain_experimental\n",
        "!pip install langchain_community --quiet\n",
        "!pip install langchainhub\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Keys"
      ],
      "metadata": {
        "id": "whqWdOt9hujw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avmSGeLcHz9d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"Your own OPEANAI_API_KEY\"\n",
        "os.environ['COHERE_API_KEY'] = \"Your own COHERE_API_KEY\"\n",
        "\n",
        "#Better way\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ['COHERE_API_KEY'] = userdata.get(\"COHERE_API_KEY\")\n",
        "#os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "#os.environ[\"LANGCHAIN_API_KEY\"]=userdata.get('LANGCHAIN_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with LLMs"
      ],
      "metadata": {
        "id": "VkWWLXWwKHFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "result=llm.invoke(\"Write a 4 line poem on AI Agents\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "bR2Xho4EKFqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Cohere\n",
        "llm=Cohere()\n",
        "result=llm(\"Write a 4 line poem on AI Agents\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "uMhO9A3cKXSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGNwlcWZH0Hw"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import OpenAI, Cohere\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Limitation\n"
      ],
      "metadata": {
        "id": "LIXK-txrhSoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm=OpenAI(temperature=0)\n",
        "print(llm.invoke(\"Who is the current president of India?\"))"
      ],
      "metadata": {
        "id": "Y8R4AXZ4hXYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(\"Who is the IPL 2025 Winner?\"))"
      ],
      "metadata": {
        "id": "YCmCOiWOhyZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sko6ltPmo7s9"
      },
      "source": [
        "# Agent Example"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step-1 : Define Tools"
      ],
      "metadata": {
        "id": "5FbE_rLaeDsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "tools = [TavilySearchResults(max_results=4)]"
      ],
      "metadata": {
        "id": "o343m1C6QyaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step-2: Define/Import the Prompt"
      ],
      "metadata": {
        "id": "N1-B3w26eJAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ[\"LANGCHAIN_API_KEY\"]=userdata.get('LANGCHAIN_API_KEY')\n",
        "from langchain import hub\n",
        "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
        "print(prompt.messages[0].prompt.template)"
      ],
      "metadata": {
        "id": "lWcJMspPQy2P",
        "outputId": "c3141909-6ace-44d2-fa71-e269f4aa4e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\n",
            "Observation: action result\n",
            "... (repeat Thought/Action/Observation N times)\n",
            "Thought: I know what to respond\n",
            "Action:\n",
            "```\n",
            "{{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Final response to human\"\n",
            "}}\n",
            "\n",
            "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step-3: Define LLM and Agent"
      ],
      "metadata": {
        "id": "2EzqH-fWeU1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "agent = create_structured_chat_agent(llm,\n",
        "                                     tools,\n",
        "                                     prompt)"
      ],
      "metadata": {
        "id": "Lzq32bIaUEHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step-4: Agent Executor"
      ],
      "metadata": {
        "id": "4CCzPZfqeczP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ],
      "metadata": {
        "id": "hv7xR5mfUVtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\": \"Who is the current president of India?\"})"
      ],
      "metadata": {
        "id": "UEo1WR7cUfbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\": \"Who is the IPL 2025 Winner?\"})"
      ],
      "metadata": {
        "id": "pO1eRHWwUnmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Traditional RAG"
      ],
      "metadata": {
        "id": "73jzLm7shdvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "XmyjMvFLmd7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load documents\n",
        "!wget https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/Microsoft_Earnings/TranscriptQandAFY25q4.pdf\n",
        "loader = PyPDFLoader(\"TranscriptQandAFY25q4.pdf\")\n",
        "pages = loader.load()\n",
        "print(\"Pages in the Document ==>\", len(pages))\n",
        "full_text =\"\"\n",
        "for page in pages:\n",
        "  full_text += page.page_content\n",
        "\n",
        "print(\"Pages\", len(pages))\n",
        "print(\"Lines\" , len(full_text.split(\"\\n\")))\n",
        "print(\"Words\" , len(full_text.split(\" \")))\n",
        "print(\"Charecters\", len(full_text))"
      ],
      "metadata": {
        "id": "ku8pQmGem020"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split text\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "print(len(chunks))"
      ],
      "metadata": {
        "id": "TlpvSWpgm6Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "1_uYOBhHnlcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Embed and store in FAISS\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "wQH9iwW5nXEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Setup RetrievalQA chain\n",
        "llm = OpenAI()\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    chain_type=\"stuff\"\n",
        ")"
      ],
      "metadata": {
        "id": "6yppes7snrtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step-5: RAG Q&A\n",
        "query = \"What is the LinkedIn revenue?\"\n",
        "response = qa_chain.invoke(query)\n",
        "print(\"ðŸ“˜ Answer:\\n\", response[\"result\"])"
      ],
      "metadata": {
        "id": "XIQ96TvjgMFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Ask a question\n",
        "query = \"What is the news about copilot adoption?\"\n",
        "response = qa_chain.invoke(query)\n",
        "print(\"ðŸ“˜ Answer:\\n\", response[\"result\"])"
      ],
      "metadata": {
        "id": "7oB202AMgL7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agentic RAG"
      ],
      "metadata": {
        "id": "--sKCH6cqqVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool"
      ],
      "metadata": {
        "id": "k1Ah0OHSobOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap the RAG chain as a Tool\n",
        "rag_tool = Tool(\n",
        "    name=\"MS_Earnings_RAG\",\n",
        "    func=qa_chain.run,\n",
        "    description=\"Useful for answering questions about MicroSoft Earnings\"\n",
        ")"
      ],
      "metadata": {
        "id": "HoUCz6yerN0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools=[rag_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "I_A4PQjurWp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the news about copilot adoption?\"\n",
        "agent_response = agent.run(query)"
      ],
      "metadata": {
        "id": "fawCWJiwrhJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Is there an impact of copilot on Microsoft Earnings?\"\n",
        "agent_response = agent.run(query)"
      ],
      "metadata": {
        "id": "7fZPLv8jrqro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding one more tool"
      ],
      "metadata": {
        "id": "b7Ks-GsJs7ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "id": "-HoOmvM3tQ1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "agent = initialize_agent(\n",
        "    tools=[rag_tool, YahooFinanceNewsTool()],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "vJb6SHWUtb2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What happened today with Microsoft stocks?\"\n",
        "agent_response = agent.run(query)"
      ],
      "metadata": {
        "id": "wBF8tekGtf2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does Microsoftâ€™s latest financial report say? Compare them with Google\"\n",
        "agent_response = agent.run(query)"
      ],
      "metadata": {
        "id": "GpUHBzcBwqac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFpa9ZlQwxXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}